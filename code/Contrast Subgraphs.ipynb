{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Networks Input\n",
    "1. Black-box function\n",
    "2. Counterfactual Search: DS - Dataset Search\n",
    "3. Counterfactual Search: OFS - Oblivious Forward Search\n",
    "3. Counterfactual Search: DFS - Data-driven Forward Search\n",
    "4. Counterfactual Search: OBS - Oblivious Backward Search\n",
    "4. Counterfactual Search: DBS - Data-driven Backward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Networks Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import graph\n",
    "data = {}\n",
    "path = '../data/AUTISM'\n",
    "path1 = path+'/asd/'\n",
    "path2 = path+'/td/'\n",
    "paths = [path2,path1]\n",
    "label = 0\n",
    "for path in paths:\n",
    "    for filename in os.listdir(path):\n",
    "        if 'DS_Store' not in filename:\n",
    "            with open(path+filename, 'r') as f:\n",
    "                if filename[-3:]=='csv':\n",
    "                    l = [[int(float(num)) for num in line.split(',')] for line in f] # if .txt\n",
    "                else:\n",
    "                    l = [[int(num) for num in line.split(' ')] for line in f] # if .csv\n",
    "                name = filename.split('.')[0]\n",
    "                data[name] = (label,np.array(l))\n",
    "    label +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Black-box function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_graph(g,v_sub):\n",
    "    '''To create the sub graph of 'g' from the list of nodes in 'v_sub'.\n",
    "    '''\n",
    "    g_sub = np.copy(g)\n",
    "    #l_1 = [el for el in v_sub]\n",
    "    l_1 = [el for el in v_sub]\n",
    "    g_sub = g_sub[np.ix_(l_1,l_1)]\n",
    "    return g_sub\n",
    "\n",
    "def feature_extraction(g):\n",
    "    ''' The classification funcion for the graph 'g'\n",
    "    '''\n",
    "    # Sub-graphs\n",
    "    td_asd = [65, 70, 99, 80, 69, 6, 7, 8, 9, 13, 77, 45, 16, 81, 78, 92, 56, 57, 60, 93, 63]\n",
    "    asd_td = [0, 36, 37, 38, 81, 40, 41, 74, 75, 76, 70, 72, 114, 20, 21, 73, 90, 28, 29]\n",
    "\n",
    "    # Induced sub-graphs\n",
    "    g_td_asd = sub_graph(g,td_asd)\n",
    "    g_asd_td = sub_graph(g,asd_td)\n",
    "\n",
    "    # Coefficients\n",
    "    a = sum([sum(i) for i in g_td_asd])/2\n",
    "    b = sum([sum(i) for i in g_asd_td])/2\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in data.items():\n",
    "    data[k] = (v[0],v[1],feature_extraction(v[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(g):\n",
    "    f = feature_extraction(g)\n",
    "    # Apply the rule\n",
    "    w_1 = -0.181742414867891\n",
    "    w_2 = 0.04327200353999672\n",
    "    bk = 3.2844839747590915 \n",
    "    x = bk + w_1*f[0] + w_2*f[1]\n",
    "    # Classify\n",
    "    if x>0:\n",
    "        return 1#,a,b #'ASD'\n",
    "    else:\n",
    "        return 0#,a,b#'TD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name_o = 'KKI_0050777'\n",
    "info = []\n",
    "results = {'pred':[],'true':[]}\n",
    "for name,graph in data.items():\n",
    "    g_o = data[name][1] # Original graph\n",
    "    y = data[name][0]\n",
    "    a,b = data[name][2]\n",
    "    y_hat= oracle(g_o)\n",
    "    #print('The graph {} with lable {} is classified as {}'.format(name,y,y_hat))\n",
    "    results['pred'].append(y_hat)\n",
    "    results['true'].append(y)\n",
    "    info.append((y_hat,y,a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1 = -0.181742414867891\n",
    "w_2 = 0.04327200353999672\n",
    "bk = 3.2844839747590915 \n",
    "l_0_a_tot = [el[2] for el in info if el[1]==0]\n",
    "l_0_b_tot = [el[3] for el in info if el[1]==0]\n",
    "l_1_a_tot = [el[2] for el in info if el[1]==1]\n",
    "l_1_b_tot = [el[3] for el in info if el[1]==1]\n",
    "l_a_tot = [el[2] for el in info]\n",
    "l_b_tot = [(bk+(w_1*el[2]))/(-w_2) for el in info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.ylim(0.0, 80.0)\n",
    "plt.xlim(00.0, 60.0)\n",
    "\n",
    "plt.plot(l_0_a_tot,l_0_b_tot,'bo',label=\"TD\")\n",
    "plt.plot(l_1_a_tot,l_1_b_tot,'ro',label=\"ASD\")\n",
    "plt.plot(l_a_tot,l_b_tot,'g-')\n",
    "\n",
    "plt.title('Scatter Plot')\n",
    "plt.ylabel('ASD_TD')\n",
    "plt.xlabel('TD_ASD')\n",
    "plt.legend()\n",
    "#plt.savefig('Scatter_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "tn, fp, fn, tp = confusion_matrix(results['true'],results['pred']).ravel()\n",
    "print('Results:\\n- {} TP;\\n- {} TN;\\n- {} FP;\\n- {} FN.'.format(tp,tn,fp,fn))\n",
    "accuracy = accuracy_score(results['true'],results['pred'])\n",
    "print('Accuracy = {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Counterfactual Search: DS - Dataset Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_edges(g):\n",
    "    '''Returns the total number of edges for undirected graphs\n",
    "    '''\n",
    "    return sum([sum(el) for el in g])/2\n",
    "\n",
    "def edit_distance(g_1,g_2):\n",
    "    '''\n",
    "    '''\n",
    "    return tot_edges(abs(g_1-g_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_distance(data,g_name):\n",
    "    ''' Sort of the datasets graph (classified in the counterfactual class y_bar) \n",
    "        by edit distance.\n",
    "    '''\n",
    "    l_dist = []\n",
    "    g = data[g_name][1] # original graph\n",
    "    y_hat = oracle(g)\n",
    "    y_bar = abs(1-y_hat)\n",
    "    l=1\n",
    "    for name,v in data.items():\n",
    "        y_i = oracle(v[1])\n",
    "        l += 1\n",
    "        if name != g_name and y_i==y_bar:\n",
    "            d = edit_distance(g,v[1])\n",
    "            l_dist.append((name,d))\n",
    "    return sorted(l_dist, key=lambda tup: tup[1]),l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results_dataset = {}\n",
    "dataset_d = {}\n",
    "k = 0\n",
    "for gname,v in data.items():\n",
    "    print(k, end=' - ')\n",
    "    k+=1\n",
    "    g = v[1] # Original graph\n",
    "    y_hat = oracle(g)\n",
    "    dim = len(g)\n",
    "    y_bar = abs(1-y_hat) # counterfactual class\n",
    "    d_bar,l = dataset_distance(data,gname)\n",
    "    name_c, d = d_bar[0]\n",
    "    g_c = v[1]\n",
    "    results_dataset[gname] = (d,y_hat,l)\n",
    "    dataset_d[gname] = name_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_list = [el[0] for el in results_dataset.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(edit_list))\n",
    "print(np.quantile(edit_list,0.25))\n",
    "print(np.quantile(edit_list,0.50))\n",
    "print(np.quantile(edit_list,0.75))\n",
    "print(max(edit_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Counterfactual Search: OFS - Oblivious Forward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def bernoulli(p):\n",
    "    ''' p is the probability of removing an edge.\n",
    "    '''\n",
    "    return True if random.random() < p else False\n",
    "\n",
    "        \n",
    "\n",
    "def forward_greedy(g_o,y_bar,k=5,lambda_g=2000,p_0=0.5):\n",
    "    '''\n",
    "    '''\n",
    "    dim = len(g_o)\n",
    "    l=0\n",
    "    \n",
    "    # Candidate counterfactual\n",
    "    g_c = np.copy(g_o)\n",
    "    r = abs(1-y_bar)\n",
    "\n",
    "    # Create add and remove sets of edges\n",
    "    g_add = []\n",
    "    g_rem = []\n",
    "    for i in range(dim):\n",
    "        for j in range(i,dim):\n",
    "            if i!=j:\n",
    "                if g_c[i][j]>0.5:\n",
    "                    g_rem.append((i,j))\n",
    "                else:\n",
    "                    g_add.append((i,j))\n",
    "    # randomize and remove duplicate\n",
    "    random.shuffle(g_add)\n",
    "    random.shuffle(g_rem)\n",
    "    \n",
    "    # Start the search\n",
    "    while(l<lambda_g):\n",
    "        ki=0\n",
    "        while(ki<k):\n",
    "            if bernoulli(p_0):\n",
    "                # remove\n",
    "                i,j = g_rem.pop(0)\n",
    "                g_c[i][j]=0\n",
    "                g_c[j][i]=0\n",
    "                g_add.append((i,j))\n",
    "                #random.shuffle(g_add)\n",
    "            else:\n",
    "                # add\n",
    "                i,j = g_add.pop(0)\n",
    "                g_c[i][j]=1\n",
    "                g_c[j][i]=1\n",
    "                g_rem.append((i,j))\n",
    "                #random.shuffle(g_rem)\n",
    "            ki+=1\n",
    "        ki=0\n",
    "        r = oracle(g_c)\n",
    "        l += 1\n",
    "        if r==y_bar:\n",
    "            #print('- A counterfactual is found!')\n",
    "            d = edit_distance(g_o,g_c)\n",
    "            return d,g_c,l\n",
    "        if len(g_rem)<1:\n",
    "            print('no more remove')\n",
    "    return 0,g_o,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lambda_g = 2000\n",
    "results_forward = {}\n",
    "for q in range(5):\n",
    "    print(q)\n",
    "    k = 0\n",
    "    results_forward_i = {}\n",
    "    for gname,v in data.items():\n",
    "        print(k, end=' - ')\n",
    "        #print('{}-- Dataset Search for {} graph ---'.format(k,gname))\n",
    "        k+=1\n",
    "        g = v[1] # Original graph\n",
    "        y_hat = oracle(g)\n",
    "        #\n",
    "        d_final,g_c_final,lambda_final = forward_greedy(g,abs(1-y_hat))\n",
    "        results_forward_i[gname] = [d_final,g_c_final,lambda_final]\n",
    "    results_forward[q] = results_forward_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_forward = {i:results_forward[i] for i in range(5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq= 5\n",
    "edit_list = []\n",
    "edit_std = []\n",
    "lambda_list = []\n",
    "lambda_std = []\n",
    "not_found = []\n",
    "for gname,v in data.items():\n",
    "    edit_i = [results_forward[q][gname][0] for q in range(qq) if results_forward[q][gname][0]!=0]\n",
    "    if len(edit_i)>0:\n",
    "        edit_list.append(sum(edit_i)/len(edit_i))\n",
    "        not_found.append(qq-len(edit_i))\n",
    "        lambda_i = [results_forward[q][gname][2] for q in range(qq) if results_forward[q][gname][0]!=0]\n",
    "        lambda_list.append(sum(lambda_i)/len(lambda_i))\n",
    "        lambda_std.append(round(np.std(lambda_i),1))\n",
    "        edit_std.append(round(np.std(edit_i),1))\n",
    "    else:\n",
    "        #edit_list.append(2000)\n",
    "        not_found.append(qq)\n",
    "        #lambda_list.append(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Edit Distance: Average')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(edit_list),np.quantile(edit_list,0.25),np.quantile(edit_list,0.50),\n",
    "                                        np.quantile(edit_list,0.75),max(edit_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lambda: Average')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(lambda_list),np.quantile(lambda_list,0.25),np.quantile(lambda_list,0.50),\n",
    "                                        np.quantile(lambda_list,0.75),max(lambda_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Edit Distance: Standard Deviation')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(edit_std),np.quantile(edit_std,0.25),np.quantile(edit_std,0.50),\n",
    "                                        np.quantile(edit_std,0.75),max(edit_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lambda: Standard Deviation')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(lambda_std),np.quantile(lambda_std,0.25),np.quantile(lambda_std,0.50),\n",
    "                                        np.quantile(lambda_std,0.75),max(lambda_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Not Found = ',not_found)\n",
    "print('Total Not Found = ',sum(not_found))\n",
    "print('Avg Not Found = ',sum(not_found)/qq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Counterfactual Search: DFS - Data-driven Forward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes frequency\n",
    "#create the two matices as the count of the frequency of each edge to be in a graph of the dataset\n",
    "dim_g = 116\n",
    "g_0 = np.zeros((dim_g,dim_g))\n",
    "g_1 = np.zeros((dim_g,dim_g))\n",
    "for k,v in data.items():\n",
    "    g = v[1]\n",
    "    y_hat = oracle(g)\n",
    "    if y_hat==0:\n",
    "        g_0 = np.add(g_0,g)\n",
    "    else:\n",
    "        g_1 = np.add(g_1,g)\n",
    "g_01 = g_0-g_1\n",
    "g_10 = g_1-g_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_01 = g_01.min()\n",
    "max_01 = g_01.max()\n",
    "g01 = np.ones((dim_g,dim_g))+(g_01-min_01)/(max_01-min_01)\n",
    "min_10 = g_10.min()\n",
    "max_10 = g_10.max()\n",
    "g10 = np.ones((dim_g,dim_g))+(g_10-min_10)/(max_10-min_10)\n",
    "prob_initial = {0:g01/g01.sum(),1:g10/g10.sum()}\n",
    "g00 = np.ones((dim_g,dim_g))\n",
    "uniform_initial_prop = {0:g00/g00.sum(),1:g00/g00.sum()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_select(g,edges,y_bar,ki,edges_prob,p_0=0.5):\n",
    "    '''\n",
    "    '''\n",
    "    edges_prob_rem = np.array([])\n",
    "    edges_prob_add = np.array([])\n",
    "    edges_add = []\n",
    "    edges_rem = []\n",
    "    e = []\n",
    "    dim = len(g)\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            if (i,j) not in edges:\n",
    "                if g[i][j]>0:\n",
    "                    edges_prob_rem = np.append(edges_prob_rem,edges_prob[1-y_bar][i][j])\n",
    "                    edges_rem.append((i,j))\n",
    "                else:\n",
    "                    edges_prob_add = np.append(edges_prob_add,edges_prob[y_bar][i][j])\n",
    "                    edges_add.append((i,j))\n",
    "    edges_prob_add = edges_prob_add/edges_prob_add.sum()\n",
    "    edges_prob_rem = edges_prob_rem/edges_prob_rem.sum()\n",
    "    #print('-- ',len(edges_rem),len(edges_add),len(edges))\n",
    "    edges_i = []\n",
    "    kii=0\n",
    "    while(kii<ki):\n",
    "        kii+=1\n",
    "        if bernoulli(p_0) and len(edges_add)>0:\n",
    "            #add\n",
    "            n = np.random.choice(range(len(edges_add)), size=1, p=edges_prob_add)[0]\n",
    "            i,j = edges_add[n]\n",
    "            g[i][j]=1\n",
    "            g[j][i]=1\n",
    "        elif len(edges_rem)>0:\n",
    "            #remove\n",
    "            n = np.random.choice(range(len(edges_rem)), size=1, p=edges_prob_rem)[0]\n",
    "            i,j = edges_rem[n]\n",
    "            g[i][j]=0\n",
    "            g[j][i]=0\n",
    "        edges.append((i,j))\n",
    "    return g,edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS(g,y_bar,edges_prob,k=10,l_max=2000):\n",
    "    '''\n",
    "    '''\n",
    "    info = []\n",
    "    gc = np.copy(g)\n",
    "    d = edit_distance(g,gc)\n",
    "    li=0\n",
    "    edges=[]\n",
    "    while(li<l_max):\n",
    "        gc,edges = DFS_select(gc,edges,y_bar,k,edges_prob,)\n",
    "        r = oracle(gc)\n",
    "        #print(li,len(edges),r)\n",
    "        li += 1\n",
    "        if r==y_bar:\n",
    "            #print('- A counterfactual is found!')\n",
    "            d = edit_distance(g_o,gc)\n",
    "            return d,gc,l\n",
    "    return 0,gc,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lambda_g = 2000\n",
    "results_prob = {}\n",
    "for q in range(3):\n",
    "    print(q)\n",
    "    k = 0\n",
    "    results_prob_i = {}\n",
    "    for gname,v in data.items():\n",
    "        print(k, end=' ')\n",
    "        #print('{}-- Dataset Search for {} graph ---'.format(k,gname))\n",
    "        k+=1\n",
    "        g = v[1] # Original graph\n",
    "        y_hat = oracle(g)\n",
    "        y_bar = abs(1-y_hat)\n",
    "        #\n",
    "        d_final,g_c_final,lambda_final = DFS(g,y_bar,prob_initial)\n",
    "#        d_final,g_c_final,lambda_final = forward_probabilistic(g,y_bar,edges_prob)\n",
    "        results_prob_i[gname] = [d_final,g_c_final,lambda_final]\n",
    "        print('->({})'.format(d_final),end=' - ')\n",
    "    results_prob[q] = results_prob_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DFS - other scores for edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_g = 116\n",
    "g_0 = np.ones((dim_g,dim_g))\n",
    "g_1 = np.ones((dim_g,dim_g))\n",
    "for k,v in data.items():\n",
    "    g = v[1]\n",
    "    y_hat = oracle(g)\n",
    "    if y_hat==0:\n",
    "        g_0 = np.add(g_0,g)\n",
    "    else:\n",
    "        g_1 = np.add(g_1,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_initial = {0:g_0/g_0.sum(),1:g_1/g_1.sum()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Edges probabilities\n",
    "# Nodes Class 0\n",
    "nodes_0_sum = np.array([sum(el) for el in g_0]).sum()\n",
    "edges_0 = g_0.ravel()/nodes_0_sum\n",
    "\n",
    "# Nodes Class 1\n",
    "nodes_1_sum = np.array([sum(el) for el in g_1]).sum()\n",
    "edges_1 = g_1.ravel()/nodes_1_sum\n",
    "\n",
    "#edges = np.array(edges)\n",
    "edges_prob = {0:edges_0, 1:edges_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "def bernoulli(p):\n",
    "    ''' p is the probability of removing an edge.\n",
    "    '''\n",
    "    return True if random.random() < p else False\n",
    "\n",
    "\n",
    "def forward_probabilistic(g_o,y_bar,edges_prob,lambda_g=2000,p_0=0.5):\n",
    "    '''\n",
    "    '''\n",
    "    dim = len(g_o)\n",
    "    edges = []\n",
    "    e = []\n",
    "    k = 0\n",
    "    for i in range(dim_g):\n",
    "        for j in range(dim_g):\n",
    "            edges.append((i,j))\n",
    "            e.append(k)\n",
    "            k+=1\n",
    "    l=0\n",
    "    \n",
    "    # Candidate counterfactual\n",
    "    g_c = np.copy(g_o)\n",
    "    r = abs(1-y_bar)\n",
    "    \n",
    "    # Start the search\n",
    "    while(l<lambda_g):\n",
    "        if bernoulli(p_0):\n",
    "            # remove\n",
    "            n = np.random.choice(e, size=1, p=edges_prob[abs(y_bar-1)])[0]\n",
    "            i,j = edges[n]\n",
    "            g_c[i][j]=0\n",
    "            g_c[j][i]=0\n",
    "        else:\n",
    "            # add\n",
    "            n = np.random.choice(e, size=1, p=edges_prob[y_bar])[0]\n",
    "            i,j = edges[n]\n",
    "            g_c[i][j]=1\n",
    "            g_c[j][i]=1\n",
    "        r = oracle(g_c)\n",
    "        l += 1\n",
    "        if r==y_bar:\n",
    "            #print('- A counterfactual is found!')\n",
    "            d = edit_distance(g_o,g_c)\n",
    "            return d,g_c,l\n",
    "    return 0,g_o,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lambda_g = 2000\n",
    "results_prob_0 = {}\n",
    "for q in range(5):\n",
    "    print(q)\n",
    "    k = 0\n",
    "    results_prob_i = {}\n",
    "    for gname,v in data.items():\n",
    "        print(k, end=' - ')\n",
    "        #print('{}-- Dataset Search for {} graph ---'.format(k,gname))\n",
    "        k+=1\n",
    "        g = v[1] # Original graph\n",
    "        y_hat = oracle(g)\n",
    "        y_bar = abs(1-y_hat)\n",
    "        dim = len(g)\n",
    "        #\n",
    "        d_final,g_c_final,lambda_final = forward_probabilistic(g,y_bar,edges_prob)\n",
    "        #d_final,g_c_final,lambda_final = forward_greedy(g,abs(1-y_hat))\n",
    "        results_prob_i[gname] = [d_final,g_c_final,lambda_final]\n",
    "    results_prob_0[q] = results_prob_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counterfactual Search: OBS - Oblivious Backward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_change_list(g1,g2):\n",
    "    edges = []\n",
    "    g_diff = abs(g1-g2)\n",
    "    dim_g = len(g1)\n",
    "    for i in range(dim_g):\n",
    "        for j in range(i,dim_g):\n",
    "            if g_diff[i][j]==1:\n",
    "                edges.append((i,j))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb(g,gc1,y_bar,k=5,l_max=2000):\n",
    "    '''\n",
    "    '''\n",
    "    gc = np.copy(gc1)\n",
    "    edges = get_change_list(g,gc)\n",
    "    d = edit_distance(g,gc)\n",
    "    random.shuffle(edges)\n",
    "    li=0\n",
    "    while(li<l_max and len(edges)>0 and d>1):\n",
    "        ki = min(k,len(edges))\n",
    "        gci = np.copy(gc)\n",
    "        edges_i = [edges.pop(0) for i in range(ki)]\n",
    "        for i,j in edges_i:\n",
    "            if gci[i][j]>0.5:\n",
    "                gci[i][j] = 0\n",
    "                gci[j][i] = 0\n",
    "            else:\n",
    "                gci[i][j] = 1\n",
    "                gci[j][i] = 1\n",
    "        r = oracle(gci)\n",
    "        li += 1\n",
    "        if r==y_bar:\n",
    "            gc = np.copy(gci)\n",
    "            d = edit_distance(g,gc)\n",
    "            #print('ok --> ',r,d,l,k)\n",
    "            info.append((r,d,li,ki))\n",
    "            k+=1\n",
    "        else:\n",
    "            d = edit_distance(g,gc)\n",
    "            info.append((r,d,li,ki))\n",
    "            if k>1:\n",
    "                k-=1\n",
    "                edges = edges + edges_i\n",
    "    return gc,edit_distance(g,gc),li,info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lambda_g = 2000\n",
    "k = 10\n",
    "info_k_dist = {}\n",
    "max_m = len(data.keys())\n",
    "r_bb = {}\n",
    "for q in range(5):\n",
    "    print(q)\n",
    "    m = 1\n",
    "    r_bb_i = {}\n",
    "    for oname,v in data.items():\n",
    "        print('{}/{}'.format(m,max_m), end=' - ')\n",
    "        m+=1\n",
    "        g = v[1]\n",
    "        y_hat = oracle(g)\n",
    "        gc_name = dataset_d[oname]\n",
    "        gc = data[gc_name][1]\n",
    "        d_initial = edit_distance(g,gc)\n",
    "        gc2,d,l,info = bb(g,gc,abs(1-y_hat))\n",
    "#        info = sum(info.values(), [])\n",
    "        d_final = edit_distance(g,gc2)\n",
    "        r_bb_i[oname] = [d_final,l,y_hat,d_initial,info,gc2]\n",
    "    r_bb[q] = r_bb_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_final,l,y_hat,d_initial,info,gc2\n",
    "qq = len(r_bb)\n",
    "ed = []\n",
    "la = []\n",
    "not_found = []\n",
    "for name in list(r_bb[0].keys()):\n",
    "    ed.append(np.array([r_bb[q][name][0] for q in range(qq)]))\n",
    "    la.append(np.array([r_bb[q][name][1] for q in range(qq)]))\n",
    "    not_found.append(np.array([name for q in range(qq) if r_bb[q][name][0]<1]))\n",
    "ed_avstd = [round(np.std(el),2) for el in ed]\n",
    "la_avstd = [round(np.std(el),2) for el in la]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_final,l,y_hat,d_initial,info,gc2\n",
    "qq = len(r_bb)\n",
    "ed_avg = []\n",
    "la_avg = []\n",
    "for name in list(r_bb[0].keys()):\n",
    "    ed_avg.append(sum([r_bb[q][name][0] for q in range(qq)])/qq)\n",
    "    la_avg.append(sum([r_bb[q][name][1] for q in range(qq)])/qq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Edit Distance: Average')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(ed_avg),np.quantile(ed_avg,0.25),np.quantile(ed_avg,0.50),\n",
    "                                        np.quantile(ed_avg,0.75),max(ed_avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lambda: Avg')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(la_avg),np.quantile(la_avg,0.25),np.quantile(la_avg,0.50),\n",
    "                                        np.quantile(la_avg,0.75),max(la_avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Edit Distance: Standard Deviation')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(ed_avstd),np.quantile(ed_avstd,0.25),np.quantile(ed_avstd,0.50),\n",
    "                                        np.quantile(ed_avstd,0.75),max(ed_avstd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lambda: Standard Deviation')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(la_avstd),np.quantile(la_avstd,0.25),np.quantile(la_avstd,0.50),\n",
    "                                        np.quantile(la_avstd,0.75),max(la_avstd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counterfactual Search: DBS - Data-driven Backward Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the two matices as the count of the frequency of each edge to be in a graph of the dataset\n",
    "dim_g = 116\n",
    "g_0 = np.zeros((dim_g,dim_g))\n",
    "g_1 = np.zeros((dim_g,dim_g))\n",
    "for k,v in data.items():\n",
    "    g = v[1]\n",
    "    y_hat = oracle(g)\n",
    "    if y_hat==0:\n",
    "        g_0 = np.add(g_0,g)\n",
    "    else:\n",
    "        g_1 = np.add(g_1,g)\n",
    "g_01 = g_0-g_1\n",
    "g_10 = g_1-g_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_01 = g_01.min()\n",
    "max_01 = g_01.max()\n",
    "g01 = np.ones((dim_g,dim_g))+(g_01-min_01)/(max_01-min_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_10 = g_10.min()\n",
    "max_10 = g_10.max()\n",
    "g10 = np.ones((dim_g,dim_g))+(g_10-min_10)/(max_10-min_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_initial = {0:g01/g01.sum(),1:g10/g10.sum()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_initial[0].min(),prob_initial[1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g00 = np.ones((dim_g,dim_g))\n",
    "uniform_initial_prop = {0:g00/g00.sum(),1:g00/g00.sum()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_edges(gc,edges,y_bar,ki,edges_prob,p_0=0.5):\n",
    "    '''\n",
    "    '''\n",
    "    gci = np.copy(gc)\n",
    "    edges_prob_rem = np.array([])\n",
    "    edges_prob_add = np.array([])\n",
    "    edges_add = []\n",
    "    edges_rem = []\n",
    "    e = []\n",
    "    gd = g - gci\n",
    "    for e in edges:\n",
    "        i,j = e\n",
    "        if gc[i][j]>0:\n",
    "            edges_prob_rem = np.append(edges_prob_rem,edges_prob[1-y_bar][i][j])\n",
    "            edges_rem.append((i,j))\n",
    "        else:\n",
    "            edges_prob_add = np.append(edges_prob_add,edges_prob[y_bar][i][j])\n",
    "            edges_add.append((i,j))\n",
    "    edges_prob_add = edges_prob_add/edges_prob_add.sum()\n",
    "    edges_prob_rem = edges_prob_rem/edges_prob_rem.sum()\n",
    "    #print('-- ',len(edges_rem),len(edges_add),len(edges))\n",
    "    edges_i = []\n",
    "    kii=0\n",
    "    while(kii<ki):\n",
    "        kii+=1\n",
    "        if bernoulli(p_0) and len(edges_add)>0:\n",
    "            #add\n",
    "            n = np.random.choice(range(len(edges_add)), size=1, p=edges_prob_add)[0]\n",
    "            i,j = edges_add[n]\n",
    "            gci[i][j]=1\n",
    "            gci[j][i]=1\n",
    "        elif len(edges_rem)>0:\n",
    "            #remove\n",
    "            n = np.random.choice(range(len(edges_rem)), size=1, p=edges_prob_rem)[0]\n",
    "            i,j = edges_rem[n]\n",
    "            gci[i][j]=0\n",
    "            gci[j][i]=0\n",
    "        edges_i.append((i,j))\n",
    "    new_edges = edges_add+edges_rem\n",
    "    return gci,new_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_prob_2(g,gc1,y_bar,edges_prob,k=5,l_max=2000):\n",
    "    '''\n",
    "    '''\n",
    "    info = []\n",
    "    gc = np.copy(gc1)\n",
    "    edges = get_change_list(g,gc)\n",
    "    d = edit_distance(g,gc)\n",
    "    li=0\n",
    "    while(li<l_max and len(edges)>0 and d>1):\n",
    "        ki = min(k,len(edges))\n",
    "        #gci,edges,edges_i = get_prob_edges(g,edges,y_bar,k,edges_prob)\n",
    "        gci,new_edges = get_prob_edges(gc,edges,y_bar,k,edges_prob)\n",
    "        r = oracle(gci)\n",
    "        li += 1\n",
    "        if r==y_bar and edit_distance(gci,gc)>0:\n",
    "            gc = np.copy(gci)\n",
    "            d = edit_distance(g,gc)\n",
    "            edges = get_change_list(g,gc)\n",
    "            #print('ok --> ',r,d,li,k)\n",
    "            info.append((r,d,li,ki))\n",
    "            k+=1\n",
    "        else:\n",
    "            #print('no --> ',r,d,li,k)\n",
    "            d = edit_distance(g,gc)\n",
    "            info.append((r,d,li,ki))\n",
    "            if k>1:\n",
    "                k-=1\n",
    "            else:\n",
    "                edges.remove(new_edges[0])\n",
    "    return gc,edit_distance(g,gc),li,info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lambda_g = 2000\n",
    "k = 2\n",
    "info_k_dist = {}\n",
    "max_m = len(data.keys())\n",
    "r_bb_prop = {}\n",
    "for q in range(5):\n",
    "    print(q)\n",
    "    m = 1\n",
    "    r_bb_i = {}\n",
    "    for oname,v in data.items():\n",
    "        print('{}/{}'.format(m,max_m), end=' - ')\n",
    "        m+=1\n",
    "        g = v[1]\n",
    "        y_hat = oracle(g)\n",
    "        gc_name = dataset_d[oname]\n",
    "        gc = data[gc_name][1]\n",
    "        d_initial = edit_distance(g,gc)\n",
    "        gc2,d,l,info = bb_prob_2(g,gc,abs(1-y_hat),prob_initial)\n",
    "        #info = sum(info.values(), [])\n",
    "        d_final = edit_distance(g,gc2)\n",
    "        r_bb_i[oname] = [d_final,l,y_hat,d_initial,info,gc2]\n",
    "    r_bb_prop[q] = r_bb_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_final,l,y_hat,d_initial,info,gc2\n",
    "qq = len(r_bb_prop)\n",
    "ed = []\n",
    "la = []\n",
    "not_found = []\n",
    "for name in list(r_bb_prop[0].keys()):\n",
    "    ed.append(np.array([r_bb_prop[q][name][0] for q in range(qq)]))\n",
    "    la.append(np.array([r_bb_prop[q][name][1] for q in range(qq)]))\n",
    "    not_found.append(np.array([name for q in range(qq) if r_bb_prop[q][name][0]<1]))\n",
    "ed_avstd = [round(np.std(el),1) for el in ed]\n",
    "la_avstd = [round(np.std(el),1) for el in la]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_final,l,y_hat,d_initial,info,gc2\n",
    "qq = len(r_bb_prop)\n",
    "ed_avg = []\n",
    "la_avg = []\n",
    "for name in list(r_bb_prop[0].keys()):\n",
    "    ed_avg.append(sum([r_bb_prop[q][name][0] for q in range(qq)])/qq)\n",
    "    la_avg.append(sum([r_bb_prop[q][name][1] for q in range(qq)])/qq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Edit Distance: Average')\n",
    "print('& {} & {} & {} & {} & {}'.format(round(np.quantile(ed_avg,0.10),1),\n",
    "                                        round(np.quantile(ed_avg,0.25),1),\n",
    "                                        round(np.quantile(ed_avg,0.50),1),\n",
    "                                        round(np.quantile(ed_avg,0.75),1),\n",
    "                                        round(np.quantile(ed_avg,0.90),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lambda: Avg')\n",
    "print('& {} & {} & {} & {} & {}'.format(round(np.quantile(la_avg,0.10),1),\n",
    "                                        round(np.quantile(la_avg,0.25),1),\n",
    "                                        round(np.quantile(la_avg,0.50),1),\n",
    "                                        round(np.quantile(la_avg,0.75),1),\n",
    "                                        round(np.quantile(la_avg,0.90),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lambda: Avg')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(la_avg),np.quantile(la_avg,0.25),np.quantile(la_avg,0.50),\n",
    "                                        np.quantile(la_avg,0.75),max(la_avg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Edit Distance: Standard Deviation')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(ed_avstd),np.quantile(ed_avstd,0.25),np.quantile(ed_avstd,0.50),\n",
    "                                        np.quantile(ed_avstd,0.75),max(ed_avstd)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lambda: Standard Deviation')\n",
    "print('& {} & {} & {} & {} & {}'.format(min(la_avstd),np.quantile(la_avstd,0.25),np.quantile(la_avstd,0.50),\n",
    "                                        np.quantile(la_avstd,0.75),max(la_avstd)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
